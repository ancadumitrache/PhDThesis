% !TEX root = ../thesis.tex
%*******************************************************
% Rezumat
%*******************************************************
\phantomsection
\manualmark
\markboth{\spacedlowsmallcaps{Rezumat}}{\spacedlowsmallcaps{Rezumat}}
\addcontentsline{toc}{chapter}{\tocEntry{Rezumat}}

\chapter*{Rezumat}

Odată cu creșterea volumului de cunoștințe disponibile pe Internet, metodele de prelucrare a limbajului natural au devenit de neprețuit pentru a facilita navigarea datelor. Sarcini cum ar fi completarea bazelor de cunoștințe și dezambiguizarea sunt rezolvate cu modele de învățare automată (engleză \textit{machine learning}) pentru prelucrarea limbajului natural. Aceste modele necesită un volum substanțial de date, în special date de referință adnotate manual, ce sunt folosite pentru învățarea, testarea și evaluarea modelelor de învățare automată.

Externalizarea în masă a datelor (engleză \textit{crowdsourcing}) a devenit recent o metodă viabilă pentru a colecta date de referință. Dar stabilirea calității adnotărilor colectate prin externalizare în masă este încă o problemă deschisă. Când pentru aceeași sarcină sunt colectate date de la mai mulți adnotatori, este probabil să apară dezacorduri și neînțelegeri. În configurările tipice de adnotare, se presupune că există un singur răspuns corect pentru fiecare sarcină și că neînțelegerile trebuie eliminate din corpusul de referință. Această abordare tradițională pentru colectarea datelor, bazată pe instrucțiuni restrictive pentru adnotare, rezultă adesea în penalizarea nejustificată a adnotatorilor calificați ce oferă o perspectivă diferită de consensul general, precum și date supra-generalizate și pierderea ambiguității inerente în limbajul natural. În consecință, datele de referință pot deveni nepotrivite pentru învățarea metodelor de prelucrare a limbajului natural.

Metodologia \textit{CrowdTruth} (adevărul mulțimii) a fost propusă pentru a efectua externalizarea în masă a datelor, păstrând în același timp neînțelegerile dinte adnotatori. \textit{CrowdTruth} se bazează pe ideea că dezacordurile nu sunt doar zgomot ce trebuie eliminat din datele de referință, ci un semnal important ce poate fi folosit pentru a capta ambiguitatea datelor. Această metodologie reprezintă sistemul de externalizare în masă ca un triunghi cu următoarele trei componente inter-conectate: adnotatori, date și adnotări. \textit{CrowdTruth} captează dezacordurile între adnotatori, care sunt apoi folosite pentru a calcula un set de măsurători ale calității pentru cele trei componente ale sistemului de externalizare în masă. De asemenea, măsurătorile \textit{CrowdTruth} țin cont de felul în care cele trei componente interacționează unele cu celelalte -- e.g. în propoziții ambigue ne așteptăm să găsim mai multe neînțelegeri între adnotatori, prin urmare adnotatorii acestor propoziții nu ar trebui considerați de calitate scăzută.

Această disertație explorează folosirea metodologiei \textit{CrowdTruth} în colectarea datelor de referință pentru învățarea și evaluarea modelelor de prelucrare a limbajului natural. În acest scop, sunt prezentate o serie de experimente cu diferite sarcini -- extragerea relațiilor din text, dezambiguizarea cadrelor semantice (engleză \textit{semantic frames}) -- și în diferite domenii -- medical, general. Aceste experimente demonstrează rolul dezacordurilor dintre adnotatori în stabilirea calității datelor, dincolo de simpla identificare a adnotatorilor de calitate scăzută.

Capitolul~\ref{chap:med-rel-ex} argumentează că eliminarea dezacordurilor din datele de referință nu este necesară pentru a obține o calitate a datelor comparabilă cu cea obținută de la experții în domeniu. Acest argument este explorat pentru extragerea relațiilor medicale din propoziții. În domeniul medical, se presupune de obicei că adnotatorii experți în domeniu sunt necesari pentru a obține cea mai bună calitate a datelor de referință. Acest capitol arată că, prin captarea dezacordurilor dintre adnotatori cu metoda \textit{CrowdTruth}, clasificatorii de relații medicale învățați cu adnotații colectate prin externalizare în masă au o performanță asemănătoare cu cei învățați cu adnotații de la experți în domeniul medical. Mai mult, clasificatorii învățați cu adnotații colectate prin externalizare în masă au o performanță mai bună decât cei învățați cu date etichetate în mod automat. De asemenea, folosirea externalizării în masă reduce costul (atât monetar cât și în timpul necesar găsirii adnotatorilor) pentru colectarea datelor.

Capitolul~\ref{chap:maj-vote} continuă cercetarea calității datelor de referință ce păstrează dezacordurile adnotatorilor. Calitatea datelor externalizate în masă aplicate pe un set divers de sarcini este comparată în două situații: când datele sunt agregate cu metoda \textit{CrowdTruth} și când datele sunt agregate cu votul majorității, o metodă ce impune consensul majorității. Capitolul demonstrează că, prin aplicarea metodologiei \textit{CrowdTruth}, datele de referință sunt mai detaliate, permițând astfel o analiză a ambiguității conținutului ce este adnotat. Mai mult, un număr crescut de adnotatori duce la creșterea și apoi stabilizarea calității adnotațiilor, în contradicție cu practica uzuală de a folosi un număr relativ mic de adnotatori.

După ce calitatea datelor externalizate în masă cu păstrarea dezacordurilor a fost demonstrată, Capitolul~\ref{chap:od-rel-ex} prezintă cum datele colectate prin metoda \textit{CrowdTruth} pot fi folosite pentru a îmbunătăți performanța unui model pentru clasificarea relațiilor din propoziții. Astfel se generalizează observațiile din Capitolul~\ref{chap:med-rel-ex}, unde s-a demonstrat că un model învățat cu adnotații colectate prin externalizare în masă rezultă într-o performanță mai bună decât învățarea cu date adnotate în mod automat cu metoda de supervizare distantă (engleză \textit{distant supervision}). Însă externalizarea în masă a datelor este un proces costisitor, prin urmare corpusurile colectate prin această metodă tind să fie de dimensiuni reduse. Capitolul~\ref{chap:od-rel-ex} descrie cum un astfel de corpus relativ mic, colectat prin externalizare în masă, poate fi utilizat pentru a corecta un corpus de dimensiuni mari pentru învățarea unui model de clasificare a relațiilor, folosind două metode diferite: (1) prin propagarea manuală a cazurilor fals pozitive și a legăturilor între relații identificate cu ajutorul adnotatorilor și (2) prin adaptarea metodei de propagare a etichetelor semantice pentru a funcționa cu date colectate folosind CrowdTruth.

În cele din urmă, Capitolul~\ref{chap:frames} explorează cum dezacordurile între adnotatori pot fi utilizate ca un indicator al ambiguității limbajului, pentru sarcina de dezambiguizare a cadrelor semantice (i.e. concepte generale ce reprezintă înțelesul cuvintelor). Similar cu Capitolul~\ref{chap:med-rel-ex}, externalizarea în masă pentru această sarcină obține date de calitate asemănătoare cu datele adnotate de experți în domeniu. O analiză calitativă a dezacordurilor dintre adnotatorii platformelor de externalizare și experți arată că neînțelegerile sunt un indicator al ambiguității atât a propozițiilor cât și a cadrelor semantice. Tratarea acestor cazuri ca și cum ar avea o singură interpretare cu valoare discretă (i.e. corect sau incorect) este nepotrivită și poate rezulta în obiective arbitrare pentru modelele cu învățare automată. 

% adevărul din neînțelegeri  - externalizarea în masă a datelor pentru prelucrarea limbajului natural

% crowdsourcing = externalizarea în masă % https://www.e-birouvirtual.ro/node/4909

% NLP = prelucrarea limbajului natural

% knowledge base = bază de cunoștințe

% disambiguation = dezambiguizare

% semantic frame = cadru semantic % http://www.diacronia.ro/ro/indexing/details/A6485/pdf

% semantic label propagation = propagarea etichetelor semantice

% gold standard = date de referință

% crowd worker / annotator = adnotator voluntar (?)

% machine learning = învățare automată

% training = instruire / învățare

% semi-supervised training = învățare supervizată parțial

% crowdsourced corpus = corpus de date colectate prin externalizare în masă

% https://ro.wikipedia.org/wiki/Învățare_automată
